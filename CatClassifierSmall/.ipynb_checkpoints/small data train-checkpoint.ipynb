{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20ce6f6-f869-4513-8b7e-d9a6f9cf1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965a2963-7bed-409d-b5ae-d23e85f33e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3a5efe-2930-486a-ae36-f5aab7ba4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5],  #0-1 to [-1,1], formula x-mean/std\n",
    "                         [0.5,0.5,0.5])    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57163ff6-273a-4a81-abe5-ed3404824e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to directories\n",
    "train_path=\"C:/Users/HP/Desktop/Extras/PythonML/CatClassifierSmall/dataset/train\"\n",
    "test_path=\"C:/Users/HP/Desktop/Extras/PythonML/CatClassifierSmall/dataset/test\"\n",
    "train_loader=DataLoader(torchvision.datasets.ImageFolder(train_path,transform=transformer),batch_size=128, shuffle = True)\n",
    "test_loader=DataLoader(torchvision.datasets.ImageFolder(test_path,transform=transformer),batch_size=128, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c7113e-14a3-4a16-8e2b-105da74c4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #categoires\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ef4e03-9d94-467a-ab52-0dff36611de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CNN network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=2):\n",
    "        super(ConvNet,self).__init__()\n",
    "\n",
    "        #OUTPUT SIZE AFTER CONVOLUTION FILETER\n",
    "        # ((w-f+2P)/s)+1\n",
    "\n",
    "        #input shape =(256,3,150,150)\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #shape=(256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #shape=(256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #shape=(256,12,150,150)\n",
    "\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #reduce the image size be factor 2\n",
    "        #shape=(256,12,75,75)\n",
    "\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #shape=(256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #shape=(256,22,75,75)\n",
    "\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #shape=(256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #shape=(256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #shape=(256,32,75,75)\n",
    "\n",
    "        self.fc=nn.Linear(in_features=32*75*75,out_features=num_classes)\n",
    "\n",
    "    #feed forward function\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        \n",
    "        output=self.pool(output)\n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "        \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "\n",
    "        #above output will be in matrix form with shape(256,32,75,75)\n",
    "        output=output.view(-1,32*75*75)\n",
    "\n",
    "        output=self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86671aa-28fc-48ae-a2ad-e4ba6ed9b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d8f9804-3a27-4814-b8c9-ba0374ab91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#optimizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a32c62d-5aa2-4c3d-aa62-1bdae89dcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8adfae-0f27-4900-b9e6-56af41e413d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation the size af training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*'))\n",
    "test_count=len(glob.glob(test_path+'/**/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47755dc5-4292-41ac-9eb7-3d5bedf68e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1873"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f9946d-eb13-40c5-9894-04461ea9f0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0 tensor(85.8664, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(3944.7561, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(6539.3496, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(9334.1719, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(11853.8789, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(15033.0908, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(16672.2012, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(17355.2988, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(18752.1133, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(21020.7227, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(22290.8711, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(22883.4746, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(23717.8223, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(24561.0156, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(24870.6328, grad_fn=<AddBackward0>)\n",
      "Epoch: 0 Train Loss: 13 Train Accuracy: 0.643440391943386 Test accuracy: 0.3539775760811532\n",
      "Train loss:  0 tensor(578.0392, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(1061.6636, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(1351.3721, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(1858.8025, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(2112.9260, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(2509.6724, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(2819.2803, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(3129.2156, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(3491.1819, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(3930.4822, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(4280.1348, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(4462.5869, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(4683.3813, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(4970.9185, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(5050.8511, grad_fn=<AddBackward0>)\n",
      "Epoch: 1 Train Loss: 2 Train Accuracy: 0.7566684812193795 Test accuracy: 0.7869727709556861\n",
      "Train loss:  0 tensor(264.7346, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(557.3906, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(700.8118, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(853.1847, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(1085.7329, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(1382.0195, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(1574.3051, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(1776.1147, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(2046.2180, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(2174.2444, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(2361.0967, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(2550.2129, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(2659.5291, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(2830.0239, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(2884.8542, grad_fn=<AddBackward0>)\n",
      "Epoch: 2 Train Loss: 1 Train Accuracy: 0.7904191616766467 Test accuracy: 0.7373198077949813\n",
      "Train loss:  0 tensor(144.1834, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(321.8506, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(711.0311, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(892.6726, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(1011.1457, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(1194.9329, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(1349.4604, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(1456.2456, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(1563.8145, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(1756.0648, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(1825.5381, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(2007.3059, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(2154.5562, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(2338.1130, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(2377.3381, grad_fn=<AddBackward0>)\n",
      "Epoch: 3 Train Loss: 1 Train Accuracy: 0.8307022318998367 Test accuracy: 0.7528029898558463\n",
      "Train loss:  0 tensor(69.6706, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(173.6736, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(281.0304, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(402.1630, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(468.3329, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(665.3704, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(747.2936, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(844.6513, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(986.9056, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(1050.5012, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(1143.3506, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(1237.2223, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(1376.4054, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(1457.4022, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(1471.0514, grad_fn=<AddBackward0>)\n",
      "Epoch: 4 Train Loss: 0 Train Accuracy: 0.8426782798040283 Test accuracy: 0.7330485851575014\n",
      "Train loss:  0 tensor(109.6745, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(177.5820, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(279.1000, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(353.8305, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(403.0232, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(463.3236, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(503.1965, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(536.6426, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(569.9279, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(623.6213, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(662.7204, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(715.7638, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(819.5236, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(896.1036, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(919.3882, grad_fn=<AddBackward0>)\n",
      "Epoch: 5 Train Loss: 0 Train Accuracy: 0.8818726183995645 Test accuracy: 0.7223705285638014\n",
      "Train loss:  0 tensor(38.9651, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(56.9394, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(101.4960, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(130.2673, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(164.5834, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(197.3668, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(215.6534, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(246.6488, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(266.1614, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(296.3088, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(327.3795, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(348.5621, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(392.4998, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(437.3040, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(446.5801, grad_fn=<AddBackward0>)\n",
      "Epoch: 6 Train Loss: 0 Train Accuracy: 0.9237887860642352 Test accuracy: 0.6593699946609717\n",
      "Train loss:  0 tensor(34.8556, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(95.1751, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(99.9504, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(140.1152, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(212.1020, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(234.7483, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(274.6809, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(366.1827, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(392.6089, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(419.5888, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(469.9725, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(506.9511, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(537.6212, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(574.3290, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(598.8890, grad_fn=<AddBackward0>)\n",
      "Epoch: 7 Train Loss: 0 Train Accuracy: 0.9188894937397931 Test accuracy: 0.7191671115856914\n",
      "Train loss:  0 tensor(7.4074, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(16.7576, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(38.1742, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(86.3977, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(116.4582, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(132.8411, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(145.0815, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(160.8685, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(215.2964, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(246.2895, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(267.2359, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(318.7939, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(336.3452, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(370.7471, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(371.8758, grad_fn=<AddBackward0>)\n",
      "Epoch: 8 Train Loss: 0 Train Accuracy: 0.9417528579205225 Test accuracy: 0.8093966898024559\n",
      "Train loss:  0 tensor(32.8963, grad_fn=<AddBackward0>)\n",
      "Train loss:  1 tensor(65.5368, grad_fn=<AddBackward0>)\n",
      "Train loss:  2 tensor(88.2732, grad_fn=<AddBackward0>)\n",
      "Train loss:  3 tensor(102.4084, grad_fn=<AddBackward0>)\n",
      "Train loss:  4 tensor(125.0283, grad_fn=<AddBackward0>)\n",
      "Train loss:  5 tensor(135.1951, grad_fn=<AddBackward0>)\n",
      "Train loss:  6 tensor(144.0619, grad_fn=<AddBackward0>)\n",
      "Train loss:  7 tensor(184.5093, grad_fn=<AddBackward0>)\n",
      "Train loss:  8 tensor(211.1249, grad_fn=<AddBackward0>)\n",
      "Train loss:  9 tensor(231.0277, grad_fn=<AddBackward0>)\n",
      "Train loss:  10 tensor(262.4505, grad_fn=<AddBackward0>)\n",
      "Train loss:  11 tensor(288.2274, grad_fn=<AddBackward0>)\n",
      "Train loss:  12 tensor(299.6396, grad_fn=<AddBackward0>)\n",
      "Train loss:  13 tensor(311.1214, grad_fn=<AddBackward0>)\n",
      "Train loss:  14 tensor(313.3919, grad_fn=<AddBackward0>)\n",
      "Epoch: 9 Train Loss: 0 Train Accuracy: 0.9515514425694066 Test accuracy: 0.8174052322477309\n"
     ]
    }
   ],
   "source": [
    "#model training and savin best model\n",
    "\n",
    "best_accuracy=0\n",
    "for epoch in range(num_epochs):\n",
    "    #evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "\n",
    "        \n",
    "\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.cpu()*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        print(\"Train loss: \",i,train_loss)\n",
    "        i+=1\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    #evaluaiton on testinf datasert\n",
    "    model.eval()\n",
    "    test_accuracy=0.0\n",
    "    for i,(images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "\n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "    test_accuracy=test_accuracy/test_count\n",
    "\n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(int(train_loss))+' Train Accuracy: '+ str(train_accuracy)+' Test accuracy: '+str(test_accuracy))\n",
    "\n",
    "    #save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637763c-1ff7-4a64-bd55-3ffeb8c42214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
